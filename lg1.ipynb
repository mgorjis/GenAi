{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_ibm import ChatWatsonx, WatsonxEmbeddings, WatsonxLLM\n",
    "\n",
    "from langchain.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"ibm/granite-3-8b-instruct\"\n",
    "url=\"https://us-south.ml.cloud.ibm.com\"\n",
    "apikey=\"0cZb46prORvZpwwPng_oLDJOxt5SmJwRqzw0gAfZKJ5_\"\n",
    "project_id=\"2adbc31f-5dc4-4e42-b730-1e5e360727fd\"\n",
    "\n",
    "parameters = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 1000,\n",
    "}\n",
    "\n",
    "model = ChatWatsonx(\n",
    "    model_id=model_id,\n",
    "    url=url,\n",
    "    apikey=apikey,\n",
    "    project_id=project_id,\n",
    "    params=parameters,\n",
    ")\n",
    "\n",
    "tavily_api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "tavilySearchAPIWrapper = TavilySearchAPIWrapper(tavily_api_key=tavily_api_key)\n",
    "search = TavilySearchResults(api_wrapper=tavilySearchAPIWrapper)\n",
    "\n",
    "tool = TavilySearchResults(api_wrapper=tavilySearchAPIWrapper,  max_results=4) #increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "abot = Agent(model, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in charlotte NC'}, 'id': 'chatcmpl-tool-9a6e12b6e2f1482dabe6d4eefc3b23d2', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in charlotte NC?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in charlotte NC?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-9a6e12b6e2f1482dabe6d4eefc3b23d2', 'type': 'function', 'function': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"weather in charlotte NC\"}'}}]}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 224, 'total_tokens': 258}, 'model_name': 'ibm/granite-3-8b-instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls'}, id='chatcmpl-8c9962f10f68e042ca2d2a0a6a796228', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in charlotte NC'}, 'id': 'chatcmpl-tool-9a6e12b6e2f1482dabe6d4eefc3b23d2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 224, 'output_tokens': 34, 'total_tokens': 258}),\n",
       "  ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Charlotte\\', \\'region\\': \\'North Carolina\\', \\'country\\': \\'United States of America\\', \\'lat\\': 35.2269, \\'lon\\': -80.8433, \\'tz_id\\': \\'America/New_York\\', \\'localtime_epoch\\': 1739930861, \\'localtime\\': \\'2025-02-18 21:07\\'}, \\'current\\': {\\'last_updated_epoch\\': 1739930400, \\'last_updated\\': \\'2025-02-18 21:00\\', \\'temp_c\\': 8.3, \\'temp_f\\': 46.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 4.0, \\'wind_kph\\': 6.5, \\'wind_degree\\': 110, \\'wind_dir\\': \\'ESE\\', \\'pressure_mb\\': 1023.0, \\'pressure_in\\': 30.21, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 40, \\'cloud\\': 75, \\'feelslike_c\\': 7.4, \\'feelslike_f\\': 45.3, \\'windchill_c\\': 6.2, \\'windchill_f\\': 43.2, \\'heatindex_c\\': 7.3, \\'heatindex_f\\': 45.2, \\'dewpoint_c\\': 0.5, \\'dewpoint_f\\': 32.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 7.6, \\'gust_kph\\': 12.2}}\"}, {\\'url\\': \\'https://weathershogun.com/weather/usa/nc/charlotte/3313/february/2025-02-19\\', \\'content\\': \\'Rainy weather, precipitation in the form of water droplets falling from the sky. Day 52°.\\'}, {\\'url\\': \\'https://world-weather.info/forecast/usa/charlotte/february-2025/\\', \\'content\\': \"Weather in Charlotte in February 2025 (North Carolina) - Detailed Weather Forecast for a Month Weather World United States Weather in Charlotte Weather in Charlotte in February 2025 Charlotte Weather Forecast for February 2025, is based on previous years\\' statistical data. +54°+43° +54°+43° +52°+43° +52°+41° +52°+41° +52°+43° +54°+46° +55°+46° +54°+45° +55°+43° +55°+46° +54°+46° +52°+45° +54°+43° +55°+45° +57°+46° +54°+46° +54°+45° +54°+43° +55°+45° +59°+48° +61°+50° +59°+50° +57°+46° +57°+46° +55°+45° +55°+46° +61°+50° Extended weather forecast in Charlotte HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in Washington, D.C.+30° Raleigh+32° Morganton+30° Shelby+37° Statesville+34° Troy+32° Fort Mill+36° Lancaster+36° Rock Hill+36° Spartanburg+41° Mooresville+34° Monroe+36° Albemarle+32° Asheboro+30° Concord+34° Forest City+36° Mount Pleasant+34° Beaumont+23° world\\'s temperature today day day Copyright © 2025 «World-Weather.info» All rights reserved. Temperature units\"}, {\\'url\\': \\'https://www.weather25.com/north-america/usa/north-carolina/charlotte?page=month&month=February\\', \\'content\\': \\'Charlotte weather in February 2025 | Weather25.com Charlotte  Charlotte Charlotte weather in February 2025 The average weather in Charlotte in February The weather in Charlotte in February is very cold with temperatures between 3°C and 12°C, warm clothes are a must. | Charlotte in February | | Charlotte in May | Temperatures in Charlotte in February Weather in Charlotte in February - FAQ The average temperature in Charlotte in February is 3/12° C. On average, there are 6 rainy days in Charlotte during February. Weather wise, is February a good time to visit Charlotte? The weather in Charlotte in February is bad. On average, there are 2 snowy days in Charlotte in February. More about the weather in Charlotte\\'}]', name='tavily_search_results_json', tool_call_id='chatcmpl-tool-9a6e12b6e2f1482dabe6d4eefc3b23d2'),\n",
       "  AIMessage(content='The current weather in Charlotte, NC is partly cloudy with a temperature of 46.9°F (8.3°C). The wind is coming from the ESE at 4.0 mph (6.5 kph). There is no precipitation and the humidity is 40%. The weather forecast for the next few days suggests a mix of sunny and cloudy conditions with temperatures ranging from 43°F to 55°F. There is a possibility of rain on some days.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 1563, 'total_tokens': 1679}, 'model_name': 'ibm/granite-3-8b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop'}, id='chatcmpl-2c10f752ada1bc81d986d234ee4b8049', usage_metadata={'input_tokens': 1563, 'output_tokens': 116, 'total_tokens': 1679})]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in Charlotte, NC is partly cloudy with a temperature of 46.9°F (8.3°C). The wind is coming from the ESE at 4.0 mph (6.5 kph). There is no precipitation and the humidity is 40%. The weather forecast for the next few days suggests a mix of sunny and cloudy conditions with temperatures ranging from 43°F to 55°F. There is a possibility of rain on some days.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'chatcmpl-tool-d71123c42607404280f44f5990449c6d', 'type': 'tool_call'}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in Los Angeles'}, 'id': 'chatcmpl-tool-16ccdbc32d65420d9893b36f847c8f4e', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF and LA?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in San Francisco is currently partly cloudy with a temperature of 59°F (15.0°C). The wind is blowing at 5.1 mph (8.3 kph) from the west-northwest. There is no precipitation and the humidity is 60%.\\n\\nIn Los Angeles, the weather is sunny with a temperature of 62.1°F (16.7°C). The wind is blowing at 7.6 mph (12.2 kph) from the west-southwest. There is no precipitation and the humidity is 62%.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Supported models: ['codellama/codellama-34b-instruct-hf', 'google/flan-t5-xl', 'google/flan-t5-xxl', 'google/flan-ul2', 'ibm/granite-13b-instruct-v2', 'ibm/granite-20b-code-instruct', 'ibm/granite-20b-multilingual', 'ibm/granite-3-2-8b-instruct-preview-rc', 'ibm/granite-3-2b-instruct', 'ibm/granite-3-8b-instruct', 'ibm/granite-34b-code-instruct', 'ibm/granite-3b-code-instruct', 'ibm/granite-8b-code-instruct', 'ibm/granite-guardian-3-2b', 'ibm/granite-guardian-3-8b', 'meta-llama/llama-2-13b-chat', 'meta-llama/llama-3-1-70b-instruct', 'meta-llama/llama-3-1-8b-instruct', 'meta-llama/llama-3-2-11b-vision-instruct', 'meta-llama/llama-3-2-1b-instruct', 'meta-llama/llama-3-2-3b-instruct', 'meta-llama/llama-3-2-90b-vision-instruct', 'meta-llama/llama-3-3-70b-instruct', 'meta-llama/llama-3-405b-instruct', 'meta-llama/llama-guard-3-11b-vision', 'mistralai/mistral-large', 'mistralai/mixtral-8x7b-instruct-v01']'''\n",
    "\n",
    "\n",
    "model_id=\"meta-llama/llama-3-3-70b-instruct\"\n",
    "url=\"https://us-south.ml.cloud.ibm.com\"\n",
    "apikey=\"0cZb46prORvZpwwPng_oLDJOxt5SmJwRqzw0gAfZKJ5_\"\n",
    "project_id=\"2adbc31f-5dc4-4e42-b730-1e5e360727fd\"\n",
    "\n",
    "parameters = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 1000,\n",
    "}\n",
    "\n",
    "model = ChatWatsonx(\n",
    "    model_id=model_id,\n",
    "    url=url,\n",
    "    apikey=apikey,\n",
    "    project_id=project_id,\n",
    "    params=parameters,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'super bowl 2024 winner'}, 'id': 'chatcmpl-tool-73a79040ce1f422cb6e5b277895024ac', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Kansas City Chiefs headquarters location'}, 'id': 'chatcmpl-tool-420138d288c1490784564eb1447b1890', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Missouri GDP'}, 'id': 'chatcmpl-tool-76c134fa2edf4111a215ad9db3035b1e', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "# Note, the query was modified to produce more consistent results. \n",
    "# Results may vary per run and over time as search information and models change.\n",
    "\n",
    "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "abot = Agent(model, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner of the Super Bowl in 2024 was the Kansas City Chiefs. The Kansas City Chiefs' headquarters is located in the state of Missouri. The GDP of Missouri is $348.5 billion.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "client = TavilyClient(api_key=tavily_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose location (try to change to your own city!)\n",
    "\n",
    "city = \"Charlotte\"\n",
    "\n",
    "query = f\"\"\"\n",
    "    what is the current weather in {city}?\n",
    "    Should I travel there today?\n",
    "    \"weather.com\"\n",
    "\"\"\"\n",
    "\n",
    "#query = f\"which team won the soccer world cup 1998? and in which country?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': {'name': 'Charlotte', 'region': 'North Carolina', 'country': 'United States of America', 'lat': 35.2269, 'lon': -80.8433, 'tz_id': 'America/New_York', 'localtime_epoch': 1739931333, 'localtime': '2025-02-18 21:15'}, 'current': {'last_updated_epoch': 1739931300, 'last_updated': '2025-02-18 21:15', 'temp_c': 7.8, 'temp_f': 46.0, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 4.0, 'wind_kph': 6.5, 'wind_degree': 110, 'wind_dir': 'ESE', 'pressure_mb': 1023.0, 'pressure_in': 30.22, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 43, 'cloud': 75, 'feelslike_c': 6.8, 'feelslike_f': 44.3, 'windchill_c': 6.2, 'windchill_f': 43.2, 'heatindex_c': 7.3, 'heatindex_f': 45.2, 'dewpoint_c': 0.5, 'dewpoint_f': 32.9, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 7.6, 'gust_kph': 12.2}}\n"
     ]
    }
   ],
   "source": [
    "# run search\n",
    "result = client.search(query, max_results=1)\n",
    "\n",
    "# print first result\n",
    "data = result[\"results\"][0][\"content\"]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"location\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"name\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"Charlotte\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"region\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"North Carolina\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"country\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"United States of America\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"lat\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m35.2269\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"lon\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m-80.8433\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"tz_id\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"America/New_York\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"localtime_epoch\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m1739931333\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"localtime\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"2025-02-18 21:15\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m},\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"current\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"last_updated_epoch\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m1739931300\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"last_updated\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"2025-02-18 21:15\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"temp_c\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m7.8\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"temp_f\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m46.0\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"is_day\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m0\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"condition\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"text\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"Partly cloudy\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"icon\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"//cdn.weatherapi.com/weather/64x64/night/116.png\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"code\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m1003\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m},\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"wind_mph\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m4.0\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"wind_kph\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m6.5\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"wind_degree\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m110\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"wind_dir\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"ESE\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"pressure_mb\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m1023.0\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"pressure_in\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m30.22\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"precip_mm\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m0.0\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"precip_in\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m0.0\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"humidity\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m43\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"cloud\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m75\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"feelslike_c\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m6.8\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"feelslike_f\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m44.3\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"windchill_c\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m6.2\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"windchill_f\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m43.2\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"heatindex_c\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m7.3\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"heatindex_f\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m45.2\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"dewpoint_c\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m0.5\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"dewpoint_f\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m32.9\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"vis_km\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m16.0\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"vis_miles\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m9.0\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"uv\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m0.0\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"gust_mph\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m7.6\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[94m\"gust_kph\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34m12.2\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "}\u001b[37m\u001b[39;49;00m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pygments import highlight, lexers, formatters\n",
    "\n",
    "# parse JSON\n",
    "parsed_json = json.loads(data.replace(\"'\", '\"'))\n",
    "\n",
    "# pretty print JSON with syntax highlighting\n",
    "formatted_json = json.dumps(parsed_json, indent=4)\n",
    "colorful_json = highlight(formatted_json,\n",
    "                          lexers.JsonLexer(),\n",
    "                          formatters.TerminalFormatter())\n",
    "\n",
    "print(colorful_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
