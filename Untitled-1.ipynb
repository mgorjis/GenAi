{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_ibm import ChatWatsonx\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames\n",
    "\n",
    "from typing import List, Sequence\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages( [\n",
    "    (\"system\", \"you are twitter expert. write a critique and recommendation for the users's tweet, always provide detailed feedback\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_messages( [\n",
    "    (\"system\", \"you are twitter expert. generate the best twitter post for the user's request. If user provides feedback, respondwith a revised vresion of your previous attempt\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a viral twitter influencer grading a tweet. Generate critique and recommendations for the user's tweet.\"\n",
    "            \"Always provide detailed recommendations, including requests for length, virality, style, etc.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a twitter techie influencer assistant tasked with writing excellent twitter posts.\"\n",
    "            \" Generate the best twitter post possible for the user's request.\"\n",
    "            \" If the user provides critique, respond with a revised version of your previous attempts.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Iran is Tehran.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 16, 'total_tokens': 27}, 'model_name': 'ibm/granite-34b-code-instruct', 'system_fingerprint': '', 'finish_reason': 'stop'}, id='chatcmpl-8acbc87c2087daf2e66e392972edd79c', usage_metadata={'input_tokens': 16, 'output_tokens': 11, 'total_tokens': 27})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {\n",
    "#     GenTextParamsMetaNames.DECODING_METHOD: \"sample\",\n",
    "#     GenTextParamsMetaNames.MAX_NEW_TOKENS: 100,\n",
    "#     GenTextParamsMetaNames.MIN_NEW_TOKENS: 1,\n",
    "#     GenTextParamsMetaNames.TEMPERATURE: 0.5,\n",
    "#     GenTextParamsMetaNames.TOP_K: 50,\n",
    "#     GenTextParamsMetaNames.TOP_P: 1,\n",
    "# }\n",
    "\n",
    "parameters = {\n",
    "    \"temperature\": 0.9,\n",
    "    \"max_tokens\": 200,\n",
    "}\n",
    "\n",
    "llm = ChatWatsonx(\n",
    "    model_id=\"ibm/granite-34b-code-instruct\",\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    apikey=\"0cZb46prORvZpwwPng_oLDJOxt5SmJwRqzw0gAfZKJ5_\",\n",
    "    project_id=\"2adbc31f-5dc4-4e42-b730-1e5e360727fd\",\n",
    "    params=parameters,\n",
    ")\n",
    "\n",
    "llm.invoke(\"what is the capital of Iran?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Iran is Tehran.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 14, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a2319ca0-9721-4f5b-beb1-ef0bec2406b1-0', usage_metadata={'input_tokens': 14, 'output_tokens': 8, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"]=key\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"what is the capital of Iran?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_chain = generation_prompt | llm\n",
    "reflect_chain = reflection_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state is a sequence of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECT = \"reflect\" \n",
    "GENERATE = \"generate\"  # nodes\n",
    "\n",
    "def generation_node(state: Sequence[BaseMessage]) :   \n",
    "    return generate_chain.invoke({\"messages\":state})\n",
    "\n",
    "\n",
    "def reflection_node(messages:Sequence[BaseMessage]) -> List[BaseMessage]:\n",
    "    print(messages)\n",
    "    res = reflect_chain.invoke({\"messages\",messages})\n",
    "    return [HumanMessage(content = res.content)]\n",
    "\n",
    "\n",
    "builder = MessageGraph()\n",
    "builder.add_node(GENERATE, generation_node)\n",
    "builder.add_node(REFLECT, reflection_node)\n",
    "builder.set_entry_point(GENERATE)\n",
    "\n",
    "def should_continue(state:Sequence[BaseMessage]) :\n",
    "    if len(state) > 5:\n",
    "        return END\n",
    "    return REFLECT\n",
    "\n",
    "builder.add_conditional_edges (GENERATE, should_continue)\n",
    "builder.add_edge(REFLECT, GENERATE)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=' Make this tweet better:\\n                     \"Persia is the oldest civilization in the world. It is the birthplace of the first human rights charter. \\n                     ', additional_kwargs={}, response_metadata={}, id='d3091c0a-6e7f-4452-833e-fb55d6809283'), AIMessage(content='\" Persia, the birthplace of human rights, boasts the world\\'s oldest civilization. Let\\'s raise awareness and celebrate our shared history! #\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 93, 'total_tokens': 131}, 'model_name': 'ibm/granite-34b-code-instruct', 'system_fingerprint': '', 'finish_reason': 'stop'}, id='chatcmpl-69bd344adf6d65ef970676b30261f313', usage_metadata={'input_tokens': 93, 'output_tokens': 38, 'total_tokens': 131})]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124m Make this tweet better:\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m                     \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPersia is the oldest civilization in the world. It is the birthplace of the first human rights charter. \u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m                     \u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n\u001b[1;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2069\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2068\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2069\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2070\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2071\u001b[0m     config,\n\u001b[0;32m   2072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2073\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2074\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2075\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2076\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2077\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2078\u001b[0m ):\n\u001b[0;32m   2079\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2080\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1724\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1725\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1726\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1727\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1728\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1729\u001b[0m         ):\n\u001b[0;32m   1730\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py:506\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    503\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    504\u001b[0m )\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py:270\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 270\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[33], line 10\u001b[0m, in \u001b[0;36mreflection_node\u001b[1;34m(messages)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreflection_node\u001b[39m(messages:Sequence[BaseMessage]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseMessage]:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(messages)\n\u001b[1;32m---> 10\u001b[0m     res \u001b[38;5;241m=\u001b[39m reflect_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m,messages})\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [HumanMessage(content \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mcontent)]\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "input = HumanMessage(content=''' Make this tweet better:\n",
    "                     \"Persia is the oldest civilization in the world. It is the birthplace of the first human rights charter. \n",
    "                     '''\n",
    ")\n",
    "response = graph.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Make this tweet better:\"\\n                                @LangChainAI\\n        â€” newly Tool Calling feature is seriously underrated.\\n\\n        After a long wait, it\\'s  here- making the implementation of agents across different models with function calling - super easy.\\n\\n        Made a video covering their newest blog post\\n\\n                                ', additional_kwargs={}, response_metadata={}, id='b795de51-cd71-477e-b1dd-0d9d1a498376'), AIMessage(content='\"ðŸš€ Exciting news from @LangChainAI! ðŸ¤– Their new Tool Calling feature is a game-changer for implementing agents across various models, simplifying function calling like never before. Check out my latest video diving into their newest blog post! #AI #Tech\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 113, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f57e7d24-9cf0-47a6-9f6a-c06a72ac24fa-0', usage_metadata={'input_tokens': 113, 'output_tokens': 59, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mMake this tweet better:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m                                @LangChainAI\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m        â€” newly Tool Calling feature is seriously underrated.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m                                \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2069\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2068\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2069\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2070\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2071\u001b[0m     config,\n\u001b[0;32m   2072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2073\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2074\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2075\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2076\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2077\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2078\u001b[0m ):\n\u001b[0;32m   2079\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2080\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1724\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1725\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1726\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1727\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1728\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1729\u001b[0m         ):\n\u001b[0;32m   1730\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py:506\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    503\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    504\u001b[0m )\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\m_gor\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py:270\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 270\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m, in \u001b[0;36mreflection_node\u001b[1;34m(messages)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreflection_node\u001b[39m(messages:Sequence[BaseMessage]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseMessage]:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(messages)\n\u001b[1;32m---> 10\u001b[0m     res \u001b[38;5;241m=\u001b[39m reflect_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m,messages})\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [HumanMessage(content \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mcontent)]\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "inputs = HumanMessage(content=\"\"\"Make this tweet better:\"\n",
    "                                @LangChainAI\n",
    "        â€” newly Tool Calling feature is seriously underrated.\n",
    "\n",
    "        After a long wait, it's  here- making the implementation of agents across different models with function calling - super easy.\n",
    "\n",
    "        Made a video covering their newest blog post\n",
    "\n",
    "                                \"\"\")\n",
    "response = graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
